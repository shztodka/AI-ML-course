{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF2HhQu/d/a3kNTpEmma/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shztodka/AI-ML-course/blob/main/fashion-mnist-classification/fashion_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies and import packages\n",
        "First we need to install the libraries we will be using. "
      ],
      "metadata": {
        "id": "At5PyV8saNAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install numpy tensorflow wandb\n",
        "\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install numpy tensorflow\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "BEpV5-mTaR8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define helper functions for logging histograms to WandB\n"
      ],
      "metadata": {
        "id": "_EwqJG7J2I8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_bar(x, y, title, x_name=\"x\", y_name=\"y\", keep_order=False):\n",
        "    if keep_order:\n",
        "        x = [f\"{idx}: {x_}\" for idx, x_ in enumerate(x)] # Make sure alphabetical sorting works\n",
        "    table = wandb.Table(\n",
        "        data=[[x, y] for x, y in zip(x, y)],\n",
        "        columns=[x_name, y_name]\n",
        "    )\n",
        "    wandb.log({title: wandb.plot.bar(table, x_name, y_name, title=title)})\n",
        "\n",
        "\n",
        "def create_histogram(data, min_value=None, max_value=None, bins=10):\n",
        "    if min_value is None:\n",
        "        min_value = data.min()\n",
        "    if max_value is None:\n",
        "        max_value = data.max()\n",
        "\n",
        "    if isinstance(bins, int):\n",
        "        bin_edges = np.linspace(min_value, max_value, num=bins)\n",
        "    else:\n",
        "        bin_edges = bins\n",
        "        \n",
        "    numbers, _ = np.histogram(data, bins=bin_edges)\n",
        "    bin_names = [f\"{lower:.1f}-{upper:.1f}\" for lower, upper in zip(bin_edges[:-1], bin_edges[1:])]\n",
        "\n",
        "    return bin_names, numbers"
      ],
      "metadata": {
        "id": "t02Z_Cbw2Ddg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA"
      ],
      "metadata": {
        "id": "UbDKOqVcj42K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downoading the dataset"
      ],
      "metadata": {
        "id": "NMd0dMyM2Zpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_raw, y_train_raw), (x_test_raw, y_test_raw) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "lf1BdnfnaVBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training data shape : ', x_train_raw.shape, y_train_raw.shape)\n",
        "print('Testing data shape : ', x_test_raw.shape, y_test_raw.shape)"
      ],
      "metadata": {
        "id": "Cbb2jidsmNEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(y_train_raw)\n",
        "num_classes = len(classes)\n",
        "print('Number of classes: ', num_classes)\n",
        "print('Classes : ', classes)"
      ],
      "metadata": {
        "id": "_TfWkbBYlZgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the training data"
      ],
      "metadata": {
        "id": "yZSCsqrCmdsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "date_and_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "wandb_run = wandb.init(\n",
        "    project=\"fashion-mnist-kreas\",\n",
        "    name=f\"data {date_and_time}\"\n",
        ")"
      ],
      "metadata": {
        "id": "pNOZP5cbwcff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['T_shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "i = 10\n",
        "print(f\"Sample {i} is number {class_names[y_train_raw[i]]}\")\n",
        "plt.imshow(x_train_raw[i])"
      ],
      "metadata": {
        "id": "1ZGQ5pz5oe4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log the datasets minimum and maximum intensities and datatype to the WandB summary\n",
        "min_value = min(x_train_raw.min(), x_test_raw.min())\n",
        "max_value = max(x_train_raw.max(), x_test_raw.max())\n",
        "wandb_run.summary[\"raw\"] = {\"min\": min_value, \"max\": max_value, \"dtype\": str(x_train_raw.dtype)}\n",
        "\n",
        "# Create a new histogram of the image pixels intensities\n",
        "bin_names, train_hist = create_histogram(x_train_raw)\n",
        "log_bar(bin_names, train_hist, \"Raw training data\", x_name=\"bin\", y_name=\"# pixels\", keep_order=True)"
      ],
      "metadata": {
        "id": "mfbQ67JV19Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocesing"
      ],
      "metadata": {
        "id": "CiBOCXRr1uJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the values to the range -1...1\n",
        "x_train_norm = x_train_raw.astype('float32') / 128 - 1\n",
        "x_test_norm = x_test_raw.astype('float32') / 128 - 1"
      ],
      "metadata": {
        "id": "XcrJOpV61QaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_norm.min(), x_train_norm.max()"
      ],
      "metadata": {
        "id": "nXpAfo1A-cnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new histogram of the modified values\n",
        "min_value = min(x_train_norm.min(), x_test_norm.min())\n",
        "max_value = max(x_train_norm.max(), x_test_norm.max())\n",
        "wandb_run.summary[\"preprocessed\"] = {\"min\": min_value, \"max\": max_value, \"dtype\": str(x_train_norm.dtype)}\n",
        "\n",
        "bin_names, train_hist = create_histogram(x_train_norm)\n",
        "log_bar(bin_names, train_hist, \"Preprocessed training data\", x_name=\"bin\", y_name=\"# pixels\", keep_order=True)"
      ],
      "metadata": {
        "id": "vzO1XcaS-hUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 10\n",
        "print(f\"Sample {i} is number {class_names[y_train_raw[i]]}\")\n",
        "plt.imshow(x_train_norm[i])\n",
        "\n",
        "\n",
        "image_list = []\n",
        "for i in range(10):\n",
        "  image = wandb.Image(x_train_norm[i], caption=f\"{class_names[y_train_raw[i]]}\")\n",
        "  image_list.append(image)\n",
        "  \n",
        "#image = wandb.Image(x_train_norm[i], caption=f\"Training sample {i}: a {class_names[y_train[i]]}\")\n",
        "wandb.log({\"Example training images (preprocessed)\": image_list})"
      ],
      "metadata": {
        "id": "99xVN527-vpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Labels"
      ],
      "metadata": {
        "id": "UXAJEfWoJR4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "num_images_per_label = Counter(y_train_raw)\n",
        "x, num_images = zip(*((str(x_), num_) for x_, num_ in sorted(num_images_per_label.items())))\n",
        "log_bar(x, num_images, \"Labels in training data\", x_name=\"Label\", y_name=\"# images\")\n",
        "\n",
        "num_images_per_label = Counter(y_test_raw)\n",
        "x, num_images = zip(*((str(x_), num_) for x_, num_ in sorted(num_images_per_label.items())))\n",
        "log_bar(x, num_images, \"Labels in test data\", x_name=\"Label\", y_name=\"# images\")"
      ],
      "metadata": {
        "id": "cQvv18XsJWys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking number of samples from different labels\n",
        "num_images_per_label = Counter(y_train_raw)\n",
        "min_number_of_labels = min(num_images_per_label.values())\n",
        "\n",
        "num_images_per_label"
      ],
      "metadata": {
        "id": "ceX0OwYh-8jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "num_classes = 10\n",
        "y_train_bin = keras.utils.to_categorical(y_train_raw, num_classes)\n",
        "y_test_bin = keras.utils.to_categorical(y_test_raw, num_classes)\n",
        "y_train_bin.shape"
      ],
      "metadata": {
        "id": "SPjqweLeMVUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_bin[1], y_train_raw[1]"
      ],
      "metadata": {
        "id": "ETkygTrKMgrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_norm[0].dtype"
      ],
      "metadata": {
        "id": "71SPpbSWL_PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train_norm\n",
        "x_test = x_test_norm\n",
        "\n",
        "y_train = y_train_bin\n",
        "y_test = y_test_bin"
      ],
      "metadata": {
        "id": "WDDnMqr7PgxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "fwsclBMvkm-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating noisy dataset.\n"
      ],
      "metadata": {
        "id": "8mcdgrxaMreH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding some noise to the training dataset.If the noise_factor is 0 the dataset will not be created.\n",
        "noise_factor = 0.5\n",
        "\n",
        "if noise_factor == 0:\n",
        "  print(\"noise_fator=\", noise_factor)\n",
        "\n",
        "else:\n",
        "  wandb_run = wandb.init(\n",
        "    project=\"fashion-mnist-kreas\",\n",
        "    name=f\"data-noisy {date_and_time}\"\n",
        "  )\n",
        "  x_train_noisy = x_train_norm + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train_norm.shape)\n",
        "  # Clip the values of the noisy images to be between -1 and 1\n",
        "  x_train_noisy = np.clip(x_train_noisy, -1., 1.)\n",
        "  x_train = x_train_noisy\n",
        "  i = 10\n",
        "  print(f\"{class_names[y_train_raw[i]]}\")\n",
        "  plt.imshow(x_train_noisy[i])\n",
        "\n",
        "  image_list = []\n",
        "  for i in range(10):\n",
        "    image = wandb.Image(x_train_noisy[i], caption=f\"{class_names[y_train_raw[i]]}\")\n",
        "    image_list.append(image)\n",
        "    \n",
        "  #image = wandb.Image(x_train_norm[i], caption=f\"Training sample (noisy) {i}: a {class_names[y_train[i]]}\")\n",
        "  wandb.log({\"Examples training images (noisy)\": image_list})\n",
        "  wandb.finish()"
      ],
      "metadata": {
        "id": "Dvx020RDMqhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "AhX2fU-LOyD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn(input_shape, output_classes, dropout):\n",
        "    dropout1=dropout + 0.25\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=input_shape),\n",
        "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Dropout(dropout),\n",
        "         \n",
        "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Dropout(dropout1),\n",
        "         \n",
        "            layers.Flatten(),\n",
        "                    \n",
        "            layers.Dense(output_classes, activation=\"softmax\"),\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "tqfGgaFXOxqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout = 0.25\n",
        "batch_size = 64 #128+128\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "wandb_run = wandb.init(\n",
        "    project=\"fashion-mnist-kreas\",\n",
        "    name=f\"training {date_and_time}\",\n",
        "    config={\"batch_size\": batch_size, \"noise_faktor\": noise_factor, \"dropout\": dropout}\n",
        ")"
      ],
      "metadata": {
        "id": "lJXk-u-JPCfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Convolutional Neural Network that\n",
        "# expects a 28x28 pixel image with 1 color chanel (gray) as input\n",
        "model = create_cnn((28, 28, 1), 10, dropout)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "# model.fit(x_train, y_train, batch_size=batch_size,\n",
        "#           epochs=epochs, validation_split=0.1,\n",
        "#           callbacks=[wandb.keras.WandbCallback()])\n",
        "\n",
        "\n",
        "\n",
        "model_results = model.fit(x_train, y_train, batch_size=batch_size, \n",
        "                          epochs=epochs, \n",
        "                          validation_data=(x_test,y_test),\n",
        "                          callbacks=[wandb.keras.WandbCallback()])"
      ],
      "metadata": {
        "id": "pLJ-Av6WPU9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results.history.keys()"
      ],
      "metadata": {
        "id": "tCWyjk4Me7qL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model_results.history['accuracy']\n",
        "val_accuracy = model_results.history['val_accuracy']\n",
        "loss = model_results.history['loss']\n",
        "val_loss = model_results.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jYMhHXEdSwQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test_norm)\n",
        "\n"
      ],
      "metadata": {
        "id": "mIyHCqbhU5RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[10]"
      ],
      "metadata": {
        "id": "SoPDQGKBWWI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "l3pyAGAqWwHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the trained model to generate predictions for the given number\n",
        "# of validation data batches (num_batches)\n",
        "val_predictions = model.predict(x_test)\n",
        "ground_truth_class_ids = y_test.argmax(axis=1)\n",
        "# take the argmax for each set of prediction scores\n",
        "# to return the class id of the highest confidence prediction\n",
        "top_pred_ids = val_predictions.argmax(axis=1)\n",
        "\n",
        "# Log confusion matrix\n",
        "# the key \"conf_mat\" is the id of the plot--do not change\n",
        "# this if you want subsequent runs to show up on the same plot\n",
        "wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
        "                        preds=top_pred_ids, y_true=ground_truth_class_ids,\n",
        "                        class_names=class_names)})\n",
        "\n",
        "\n",
        "\n",
        "# cm = wandb.plot.confusion_matrix(\n",
        "#     y_true=y_test_bin,\n",
        "#     preds=predictions,\n",
        "#     class_names=class_names)\n",
        "    \n",
        "# wandb.log({\"conf_mat\": cm})"
      ],
      "metadata": {
        "id": "pj8ORkK5WTnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "9N-d4SDPpscf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-5vrSE2nS9gp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}